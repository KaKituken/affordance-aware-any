model:
  base_learning_rate: 1.25e-4
  target: ldm.models.diffusion.ddpm.LatentDiffusion
  params:
    # ckpt_path: /n/holyscratch01/pfister_lab/jixuan/logs/bs48/2023-09-07T11-00-23_putany/checkpoints/trainstep_checkpoints/epoch=000023-step=000010000.ckpt # point this to stable diffusion ckpt
    ckpt_path: /n/holyscratch01/pfister_lab/jixuan/checkpoint/sd-v1-5-inpainting.ckpt
    ignore_keys:
      - "load_maximally"
      - "cond_stage_model"
      # - "model.diffusion_model.input_blocks.0.0.weight"
    linear_start: 0.00085
    linear_end: 0.0120
    num_timesteps_cond: 1
    log_every_t: 200
    timesteps: 1000
    first_stage_key: groundtruth
    cond_stage_key:
      # left
      concat:
        # - key: masked_image
        #   encoder: first
        # - key: mask
        #   encoder: re scale
        - key: background
          encoder: first
        # sample from three different types of prompts (how to deal with null prompt?)
        - key: mask
          encoder: rescale
        - key: bbox
          encoder: coor2area
        - key: point
          encoder: heatmap
        - key: blank
          encoder: blank
      # condition
      crossattn:
        - key: foreground
          encoder: cond
    conditioning_key: hybrid  # use both concat & crossattn
    # conditioning_key: concat  # debug
    sample_cond:
      - key: point
        p: 1
      - key: bbox
        p: 0
      - key: mask
        p: 0
    image_size: 16
    channels: 4
    cond_stage_trainable: false   # Note: different from the one we trained before
    monitor: val/loss_simple_ema
    loss_type: balance
    scale_factor: 0.18215
    use_ema: True         # stable diffusion inference sets it to False
    
    scheduler_config: # 10000 warmup steps
      target: ldm.lr_scheduler.LambdaLinearScheduler
      params:
        warm_up_steps: [ 5000 ]
        cycle_lengths: [ 10000000000000 ] # incredibly large number to prevent corner cases
        f_start: [ 1.e-6 ]
        f_max: [ 1. ]
        f_min: [ 1. ]

    unet_config:
      target: ldm.modules.diffusionmodules.openaimodel.UNetModel
      params:
        image_size: 16
        in_channels: 9
        out_channels: 4
        model_channels: 320
        attention_resolutions: [ 4, 2, 1 ]
        num_res_blocks: 2
        channel_mult: [ 1, 2, 4, 4 ]
        num_heads: 8
        use_spatial_transformer: True
        transformer_depth: 1
        raw_context_dim: 1024
        context_dim: 768
        use_checkpoint: False
        legacy: False
    
    first_stage_config:
      target: ldm.models.autoencoder.AutoencoderKL
      params:
        embed_dim: 4
        monitor: val/rec_loss
        ddconfig:
          double_z: true
          z_channels: 4
          resolution: 128
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult:
          - 1
          - 2
          - 4
          - 4
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity

    cond_stage_config:
      target: ldm.modules.encoders.modules.FrozenHFCLIPImageEmbedder
    
    rescale_stage_config:
      target: ldm.modules.encoders.modules.SpatialRescaler
      params:
        n_stages: 3 # 256 -> 32; 128 -> 16
        method: 'bilinear'
        augment: true

    coor2area_stage_config:
      target: ldm.modules.encoders.modules.Coor2Area
      params:
        target_size: [16, 16]
        augment: true
    
    heatmap_stage_config:
      target: ldm.modules.encoders.modules.GuassHeatmapper
      params: 
        target_size: [16, 16]
        sigma: 1.3
        augment: true
    
    blank_stage_config:
      target: ldm.modules.encoders.modules.BlankGenerator
      params:
        target_size: [16, 16]

data:
  target: main.DataModuleFromConfig
  params:
    batch_size: 512
    num_workers: 15
    wrap: false
    train:
      target: ldm.data.fbp.ImageVideoWrapper
      params:
        image_cfg:
          fbp_path: '/n/holyscratch01/pfister_lab/jixuan/dataset/FBP_img_src' # point to data
          gt_path: '/n/holylfs05/LABS/pfister_lab/Lab/coxfs01/pfister_lab2/Lab/jixuan/dataset/image/SA1B'
          num_folder: 550
          # num_folder: 1
          transform:
            foreground:
              - Resize:
                  fix_size:
                  - 224
                  - 224
              - RandomResize:
                  factor:
                  - 0.8
                  - 1.2
                  isotropic: true
                  prob: 0.4
              - RandomRotation:
                  angle: 30
                  prob: 0.4
              - RandomResize:
                  factor:
                  - 0.8
                  - 1.2
                  isotropic: false
                  prob: 0.2
              - RandomCutout:
                  cut_factor:
                  - 0.1
                  - 0.5
                  prob: 0.2
              - CropOrPad:
                  fix_size:
                  - 224
                  - 224
              - Brightness:
                  brightness: 0.5
                  prob: 0.2
              - Contrast:
                  contrast: 0.5
                  prob: 0.2
              - Saturation:
                  saturation: 0.5
                  prob: 0.2
              - GaussianBlur:
                  kernel_size: 3
                  prob: 0.1
              - CLIPImage:
                  path: openai/clip-vit-large-patch14
                  return_tensors: pt
                  padding: False
              - AddNoise:
                  noise: 0.1
                  prob: 0.1
            background_with_groundtruth:
              - ResizeWithAnn:
                  size: 128
              - CropWithAnn:
                  size: 128
              - CropToMultipleWithAnn:
                  factor: 8
              - ToTensorWithAnn: {}
              - RescaleWithAnn:
                  scale_range:
                  - -1
                  - 1
        video_cfg:
          bg_path: '/n/holyscratch01/pfister_lab/jixuan/dataset/FBP_video_src'
          fg_path: '/n/holyscratch01/pfister_lab/jixuan/dataset/FBP_video_src'
          gt_path: '/n/holyscratch01/pfister_lab/jixuan/dataset/FBP_video_src'
          mask_path: '/n/holyscratch01/pfister_lab/jixuan/dataset/FBP_video_src'
          ann_path: '/n/holyscratch01/pfister_lab/jixuan/dataset/FBP_video_src'
          transform:
            foreground:
              - Resize:
                  fix_size:
                  - 224
                  - 224
              - RandomResize:
                  factor:
                  - 0.8
                  - 1.2
                  isotropic: true
                  prob: 0.4
              - RandomRotation:
                  angle: 30
                  prob: 0.4
              - RandomResize:
                  factor:
                  - 0.8
                  - 1.2
                  isotropic: false
                  prob: 0.2
              - RandomCutout:
                  cut_factor:
                  - 0.1
                  - 0.5
                  prob: 0.2
              - CropOrPad:
                  fix_size:
                  - 224
                  - 224
              - Brightness:
                  brightness: 0.5
                  prob: 0.2
              - Contrast:
                  contrast: 0.5
                  prob: 0.2
              - Saturation:
                  saturation: 0.5
                  prob: 0.2
              - GaussianBlur:
                  kernel_size: 3
                  prob: 0.1
              - CLIPImage:
                  path: openai/clip-vit-large-patch14
                  return_tensors: pt
                  padding: False
              - AddNoise:
                  noise: 0.1
                  prob: 0.1
            background_with_groundtruth:
              - ResizeWithAnn:
                  size: 128
              - CropWithAnn:
                  size: 128
              - CropToMultipleWithAnn:
                  factor: 8
              - ToTensorWithAnn: {}
              - RescaleWithAnn:
                  scale_range:
                  - -1
                  - 1
        ratio: 1
    validation:
      target: ldm.data.fbp.ImageVideoWrapper
      params:
        image_cfg:
          fbp_path: '/n/holyscratch01/pfister_lab/jixuan/dataset/FBP_img_valset' # point to data
          gt_path: '/n/holylfs05/LABS/pfister_lab/Lab/coxfs01/pfister_lab2/Lab/jixuan/dataset/image/SA1B'
          num_folder: 2
          mode: val
          transform:
            foreground:
              - Resize:
                  fix_size:
                  - 224
                  - 224
              - CLIPImage:
                  path: openai/clip-vit-large-patch14
                  return_tensors: pt
                  padding: False
            background_with_groundtruth:
              - ResizeWithAnn:
                  size: 128
              - CropWithAnn:
                  size: 128
              - CropToMultipleWithAnn:
                  factor: 8
              - ToTensorWithAnn: {}
              - RescaleWithAnn:
                  scale_range:
                  - -1
                  - 1
        video_cfg:
          bg_path: '/n/home11/jxhe/insert-any/dataset-builder/video_data/FBP_video/background'
          fg_path: '/n/home11/jxhe/insert-any/dataset-builder/video_data/FBP_video/foreground'
          gt_path: '/n/home11/jxhe/insert-any/dataset-builder/video_data/FBP_video/groundtruth'
          mask_path: '/n/home11/jxhe/insert-any/dataset-builder/video_data/FBP_video/mask'
          ann_path: '/n/home11/jxhe/insert-any/dataset-builder/video_data/FBP_video/prompt/prompt.json'
        ratio: 1
lightning:
  callbacks:
    metrics_over_trainsteps_checkpoint:
      target: pytorch_lightning.callbacks.ModelCheckpoint
      params:
        every_n_train_steps: 10000
 
    image_logger:
      target: main.ImageLogger
      params:
        batch_frequency: 2000
        # batch_frequency: 1
        max_images: 8
        increase_log_steps: False
    
    fid_test:
      target: main.FIDCallback
      params:
        batch_size: 512
        batch_freq: 800
        num_workers: 2
        ddim_steps: 200
        max_batch: 4
        cfg_scales:
          - 4.0
        calc_fid_score: false
        gt_dir: '/n/holyscratch01/pfister_lab/jixuan/fid/bs1024_full/'
        pd_dir: '/n/holyscratch01/pfister_lab/jixuan/fid/bs1024_full/'
        dataset_cfg:
          target: ldm.data.fbp.ImageVideoWrapper
          params:
            image_cfg:
              fbp_path: '/n/holyscratch01/pfister_lab/jixuan/dataset/FBP_img_testset' # point to data
              gt_path: '/n/holylfs05/LABS/pfister_lab/Lab/coxfs01/pfister_lab2/Lab/jixuan/dataset/image/SA1B'
              num_folder: 2
              mode: 'val'
              transform:
                foreground:
                  - Resize:
                      fix_size:
                      - 224
                      - 224
                  - CLIPImage:
                      path: openai/clip-vit-large-patch14
                      return_tensors: pt
                      padding: False
                background_with_groundtruth:
                  - ResizeWithAnn:
                      size: 128
                  - CropWithAnn:
                      size: 128
                  - CropToMultipleWithAnn:
                      factor: 8
                  - ToTensorWithAnn: {}
                  - RescaleWithAnn:
                      scale_range:
                      - -1
                      - 1
            video_cfg:
              bg_path: '/n/home11/jxhe/insert-any/dataset-builder/video_data/FBP_video/background'
              fg_path: '/n/home11/jxhe/insert-any/dataset-builder/video_data/FBP_video/foreground'
              gt_path: '/n/home11/jxhe/insert-any/dataset-builder/video_data/FBP_video/groundtruth'
              mask_path: '/n/home11/jxhe/insert-any/dataset-builder/video_data/FBP_video/mask'
              ann_path: '/n/home11/jxhe/insert-any/dataset-builder/video_data/FBP_video/prompt/prompt.json'
            ratio: 1

  trainer:
    strategy: ddp_find_unused_parameters_false
    max_epochs: -1
    benchmark: True
    accumulate_grad_batches: 1
    val_check_interval: 200
    # gpus: 2
    # num_nodes: 2